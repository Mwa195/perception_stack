# perception_stack
# **Object Tracking and Speed Estimation in ROS2**

## **ğŸ“Œ Overview**
This ROS2-based project performs **real-time object tracking and speed estimation** using:
- **Semantic Segmentation** to detect objects in a scene.
- **DeepSORT Tracking** to assign IDs and track objects across frames.
- **Optical Flow (Lucas-Kanade)** to estimate object speeds.
- **Data Fusion** to combine tracked object positions and speed estimates.
- **Video Streaming** to publish real-time camera feed.

The system uses **ROS2 Jazzy** and subscribes to image feeds to detect, track, and estimate the speed of multiple moving objects.

---

## **ğŸ“‚ Project Structure**
```
ros2_ws/
â”‚-- src/
â”‚   â”œâ”€â”€ robot_oops_system/
â”‚   â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”‚   â”œâ”€â”€ data_fusion.py
â”‚   â”‚   â”‚   â”œâ”€â”€ object_tracker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ optical_flow_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ streamer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_segmentation_dl.py
â”‚   â”‚   â”œâ”€â”€ package.xml
â”‚   â”‚   â”œâ”€â”€ setup.py
â”‚   â”‚   â”œâ”€â”€ setup.cfg
â”‚   â”œâ”€â”€ my_interfaces_pkg/
â”‚   â”‚   â”œâ”€â”€ msg/
â”‚   â”‚   â”‚   â”œâ”€â”€ TrackedObject.msg
â”‚   â”‚   â”‚   â”œâ”€â”€ TrackedObjects.msg
â”‚   â”‚   â”‚   â”œâ”€â”€ ObjectData.msg
â”‚   â”‚   â”‚   â”œâ”€â”€ ObjectsData.msg
â”‚   â”‚   â”‚   â”œâ”€â”€ ObjectSpeed.msg
â”‚   â”‚   â”‚   â”œâ”€â”€ ObjectsSpeeds.msg
â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”‚   â”œâ”€â”€ package.xml
â”‚-- README.md  # Project Documentation
```

---

## **ğŸš€ Setup Instructions**
### **1ï¸âƒ£ Install Dependencies**
```bash
sudo apt update && sudo apt install -y \
    python3-opencv \
    ros-jazzy-cv-bridge \
    ros-jazzy-rclpy \
    ros-jazzy-sensor-msgs \
    python3-pip
pip install torch torchvision torchaudio deepsort-realtime
```
### **2ï¸âƒ£ Clone the Repository**
```bash
cd ~/ros2_ws/src  # Navigate to your workspace
git clone https://github.com/Mwa195/perception_stack.git
cd .. && colcon build --symlink-install
source install/setup.bash
```

### **3ï¸âƒ£ Run the System**
Start each node in separate terminals:
```bash
# Start the Video Streaming Node
ros2 run robot_oops_system streamer_node

# Start the Segmentation Node
ros2 run robot_oops_system semantic_segmentation_dl

# Start the Object Tracking Node
ros2 run robot_oops_system object_tracker

# Start the Optical Flow Node
ros2 run robot_oops_system optical_flow_node

# Start the Data Fusion Node
ros2 run robot_oops_system data_fusion
```

---

## **ğŸ›  Nodes & Functionality**

### **ğŸ“¡ Video Streaming Node** (`streamer.py`)
- **Publishes to:**
  - `/camera_feed` (real-time video frames)
- **Key Features:**
  - Captures live video from a connected camera.
  - Publishes frames as ROS2 Image messages.

### **ğŸ¨ Segmentation Node** (`semantic_segmentation_dl.py`)
- **Subscribes to:**
  - `/camera_feed` (raw image)
- **Publishes to:**
  - `/segmentation_mask` (processed segmentation output)
- **Key Features:**
  - Uses **DeepLabV3+** for **semantic segmentation**.
  - Generates color-coded masks for detected objects.

### **ğŸ”µ Object Tracking Node** (`object_tracker.py`)
- **Subscribes to:**
  - `/camera_feed` (raw image)
  - `/segmentation_mask` (semantic segmentation mask)
- **Publishes to:**
  - `/tracked_objects` (IDs, class labels, bounding boxes)
- **Key Features:**
  - Extracts objects from the segmentation mask.
  - Assigns a **unique ID** using **DeepSORT Tracker**.
  - Maintains **stable IDs** for objects as long as they remain in the frame.
  - Reuses the **lowest available ID** when an object exits and a new one appears.

### **ğŸŸ¢ Optical Flow Node** (`optical_flow_node.py`)
- **Subscribes to:**
  - `/camera_feed` (raw image)
  - `/tracked_objects` (object bounding boxes)
- **Publishes to:**
  - `/tracked_speeds` (object ID, estimated speed)
- **Key Features:**
  - Uses **Lucas-Kanade Optical Flow** to estimate object speeds.
  - Computes speed in **km/h**.
  - Filters out small movements to reduce noise.

### **ğŸŸ£ Data Fusion Node** (`data_fusion.py`)
- **Subscribes to:**
  - `/tracked_objects` (object positions)
  - `/tracked_speeds` (object speeds)
- **Publishes to:**
  - `/objects_list` (merged object position & speed data)
- **Key Features:**
  - Merges object tracking and speed data into a unified message.
  - Ensures correct speed association with the **same tracked ID**.

---

## **ğŸ“œ Message Definitions**
### **ğŸ“ Tracked Objects** (`TrackedObjects.msg`)
```yaml
TrackedObject[] objects
```
### **ğŸ“ Tracked Object** (`TrackedObject.msg`)
```yaml
int32 id
string class_label
float64 xmin
float64 ymin
float64 xmax
float64 ymax
```
### **ğŸ“ Object Speed** (`ObjectSpeed.msg`)
```yaml
int32 id
float32 speed_kmh
```
### **ğŸ“ Objects Speeds** (`ObjectsSpeeds.msg`)
```yaml
ObjectSpeed[] objects
```
### **ğŸ“ Object Data** (`ObjectData.msg`)
```yaml
int32 id
string class_label
float32 speed_kmh
float64 xmin
float64 ymin
float64 xmax
float64 ymax
```
### **ğŸ“ Objects Data** (`ObjectsData.msg`)
```yaml
ObjectData[] objects
```

---

## **ğŸ‘¨â€ğŸ’» Contributors**
- **MWA, Adham, Mazen, Rewan, and Fayrouz**

---

## **ğŸ“Œ Future Work**
- Improve **speed estimation accuracy** using Kalman Filtering.
- Add **real-world unit calibration** for distance scaling.
- Integrate with a **3D perception pipeline** for depth-based tracking.

---

## **ğŸ“œ License**
This project is licensed under the **MIT License**. Feel free to modify and improve it!

---

ğŸš€ **Enjoy building with ROS2!**





